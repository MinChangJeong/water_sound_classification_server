{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGr0zxXBMKfy",
        "outputId": "1e16cc86-3fcc-4036-8a00-d7b1ca84ac0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.7.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from noisereduce) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->noisereduce) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->noisereduce) (4.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->noisereduce) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->noisereduce) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->noisereduce) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "pip install noisereduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "C5HmXo3LOx_p"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import noisereduce as nr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "YEfuujwmO0BN"
      },
      "outputs": [],
      "source": [
        "import noisereduce as nr\n",
        "\n",
        "# 데이터 로드 및 Spectrogram 추출 함수\n",
        "def load_and_extract_features(file_paths):\n",
        "    spectrograms = []\n",
        "    for file_path in file_paths:\n",
        "        waveform, sample_rate = librosa.load(file_path, sr=None)\n",
        "        spectrogram = librosa.feature.melspectrogram(y=waveform, sr=sample_rate)\n",
        "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "        resized_spectrogram = np.resize(spectrogram, (128, 128, 1))  # CNN 모델에 맞게 크기 조정\n",
        "        spectrograms.append(resized_spectrogram)\n",
        "    return np.array(spectrograms)\n",
        "\n",
        "# CNN 모델 생성 함수\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "0vRE3ii_O1Oo"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "train_file_paths_1 = [f\"/content/{str(i).zfill(3)}.wav\" for i in range(1, 21)]\n",
        "test_file_paths_1 = [f\"/content/{str(i).zfill(3)}.wav\" for i in range(21, 31)]\n",
        "\n",
        "train_file_paths_2 = [f\"/content/T{i:03d}.wav\" for i in range(1, 11)]\n",
        "test_file_paths_2 = [f\"/content/T{i:03d}.wav\" for i in range(11, 28)]\n",
        "\n",
        "train_file_paths = train_file_paths_1 + train_file_paths_2\n",
        "test_file_paths = test_file_paths_1 + test_file_paths_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "eEmAOUDPPnA9"
      },
      "outputs": [],
      "source": [
        "data = load_and_extract_features(train_file_paths)\n",
        "labels = [1] * 20 + [0] * 10  # 정답지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2vxo70rOSHS",
        "outputId": "518e06a3-3954-46ff-b12d-7f3dc55ad9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6671 - accuracy: 0.5417 - val_loss: 226.2304 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 42.3689 - accuracy: 0.8333 - val_loss: 107.6465 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 20.1793 - accuracy: 0.8333 - val_loss: 39.3441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.5254 - accuracy: 0.8333 - val_loss: 10.0152 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9833 - accuracy: 0.8333 - val_loss: 0.4763 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.8363 - accuracy: 0.1667 - val_loss: 0.9559 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4439 - accuracy: 0.8750 - val_loss: 6.3094 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.8564 - accuracy: 0.8333 - val_loss: 3.4163 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.4299 - accuracy: 0.8333 - val_loss: 1.8721 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3390 - accuracy: 0.8333 - val_loss: 1.3739 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5971d5aa10>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CNN 모델 생성\n",
        "input_shape = (128, 128, 1)  # CNN 모델에 맞는 입력 형태\n",
        "model = create_cnn_model(input_shape)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(data, np.array(labels), epochs=10, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yWnuVktR_7d"
      },
      "outputs": [],
      "source": [
        "# 특정 음성 파일의 물소리 판별\n",
        "def predict_sound(file_path):\n",
        "    # 파일 로드 및 전처리\n",
        "    waveform, sample_rate = librosa.load(file_path, sr=None)\n",
        "    spectrogram = librosa.feature.melspectrogram(y=waveform, sr=sample_rate)\n",
        "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "    resized_spectrogram = np.resize(spectrogram, (128, 128))\n",
        "\n",
        "    # 모델에 입력 형태에 맞게 차원 재구성\n",
        "    input_data = resized_spectrogram[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "    # 예측\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # 결과 출력\n",
        "    if prediction > 0.8:\n",
        "        print(f\"The sound in {file_path} is classified as 'water sound'.\")\n",
        "    else:\n",
        "        print(f\"The sound in {file_path} is classified as 'non-water sound'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mPyhBkjPwp3"
      },
      "outputs": [],
      "source": [
        "# 모델 예측\n",
        "new_spectrograms = generate_spectrograms(test_file_paths)\n",
        "preprocessed_new_spectrograms = preprocess_spectrograms(new_spectrograms)\n",
        "\n",
        "predictions = model.predict(np.array(preprocessed_new_spectrograms))\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk5q2IzyRuZ7",
        "outputId": "cb1476b1-8b0a-4b95-ddf9-e3ab291de415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sound in /content/021.wav is classified as 'water sound'.\n",
            "The sound in /content/022.wav is classified as 'water sound'.\n",
            "The sound in /content/023.wav is classified as 'water sound'.\n",
            "The sound in /content/024.wav is classified as 'water sound'.\n",
            "The sound in /content/025.wav is classified as 'water sound'.\n",
            "The sound in /content/026.wav is classified as 'non-water sound'.\n",
            "The sound in /content/027.wav is classified as 'water sound'.\n",
            "The sound in /content/028.wav is classified as 'water sound'.\n",
            "The sound in /content/029.wav is classified as 'water sound'.\n",
            "The sound in /content/030.wav is classified as 'water sound'.\n",
            "The sound in /content/T011.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T012.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T013.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T014.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T015.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T016.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T017.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T018.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T019.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T020.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T021.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T022.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T023.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T024.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T025.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T026.wav is classified as 'non-water sound'.\n",
            "The sound in /content/T027.wav is classified as 'water sound'.\n"
          ]
        }
      ],
      "source": [
        "for file_path, prediction in zip(test_file_paths, predictions):\n",
        "    if prediction >= 0.89:\n",
        "        print(f\"The sound in {file_path} is classified as 'water sound'.\")\n",
        "    else:\n",
        "        print(f\"The sound in {file_path} is classified as 'non-water sound'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "04jBw372SlFn"
      },
      "outputs": [],
      "source": [
        "model.save('water_saver.keras')  # 'water_saver.keras' 파일로 저장"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
